{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Coders - Lesson 1 Notes\n",
    "Look at the book as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What you don't need, to do deep learning:\n",
    "\n",
    "|Myth (don't need) | Truth|\n",
    "|------------------|------|\t\n",
    "Lots of math | Just high school math is sufficient|\n",
    "Lots of data | We've seen record-breaking results with <50 items of data|\n",
    "Lots of expensive computers | You can get what you need for state of the art work for free|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where is deep learning the best-known approach? (Is there any point learning Deep Learning?)\n",
    "Deep learning has power, flexibility, and simplicity. That's why we believe it should be applied across many disciplines. These include the social and physical sciences, the arts, medicine, finance, scientific research, and many more. Here's a list of some of the thousands of tasks in different areas at which deep learning, or methods heavily using deep learning, is now the best in the world:\n",
    "\n",
    "* **Natural language processing (NLP)** Answering questions; speech recognition; summarizing documents; classifying documents; finding names, dates, etc. in documents; searching for articles mentioning a concept\n",
    "\n",
    "* **Computer vision** Satellite and drone imagery interpretation (e.g., for disaster resilience); face recognition; image captioning; reading traffic signs; locating pedestrians and vehicles in autonomous vehicles\n",
    "\n",
    "* **Medicine** Finding anomalies in radiology images, including CT, MRI, and X-ray images; counting features in pathology slides; measuring features in ultrasounds; diagnosing diabetic retinopathy\n",
    "\n",
    "* **Biology** Folding proteins; classifying proteins; many genomics tasks, such as tumor-normal sequencing and classifying clinically actionable genetic mutations; cell classification; analyzing protein/protein interactions\n",
    "\n",
    "* **Image generation** Colorizing images; increasing image resolution; removing noise from images; converting images to art in the style of famous artists\n",
    "\n",
    "* **Recommendation systems** Web search; product recommendations; home page layout\n",
    "\n",
    "* **Playing games** Chess, Go, most Atari video games, and many real-time strategy games\n",
    "\n",
    "* **Robotics** Handling objects that are challenging to locate (e.g., transparent, shiny, lacking texture) or hard to pick up\n",
    "\n",
    "* **Other applications** Financial and logistical forecasting, text to speech, and much more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks: a breif history\n",
    "n 1943 Warren McCulloch, a neurophysiologist, and Walter Pitts, a logician, teamed up to develop a mathematical model of an artificial neuron. In their paper \"A Logical Calculus of the Ideas Immanent in Nervous Activity\" they declared that:\n",
    "\n",
    "> \"Because of the 'all-or-none' character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Images/chapter7_neuron.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"Images/chapter7_neuron.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the history (which although important, isn't that necessary to learn), go through the book or online course yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Software Stack\n",
    " \n",
    "In the framework of fastai, the product stack is quite minimal, going from the most broad to the least broad below:\n",
    "* **Python**\n",
    "    * Extremely extensible, and allows for many framworks to be based ontop of it\n",
    "* **PyTorch**\n",
    "  * The fastest growing Machine Learning/Deep Learning framework (With a lot of industry backing). Although less mature compared to TensorFlow, it is backed by large companies, and is easier to work with. Less 'bogged down' and 'bloated'.\n",
    "  * Most new models and development are done for PyTorch, rather than TensorFlow\n",
    "* **fastai**\n",
    "  * A framework built on top of PyTorch, and allows for the easier development of Deep Learning models specifically.\n",
    "  * Allows for the quicker development (via a higher level API)\n",
    "  * fastai is incredibly powerful, and it allows for people to learn/develop etc.\n",
    "    * **Layered API**\n",
    "      * Allows for people to have a simpler base level, while being able to go deeper (from very high level work, to extremely low level research and state of the art development)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a GPU deep learning server\n",
    "Most things require using a GPU (of which has to be a Nvidia GPU, due to the extensive use of CUDA). It is recommended not to buy one right away (or to even set up a GPU that you may have laying around). For this course, I will be using my secondary machine, which I have set up (more because of my interest in hardware and Linux), which has a Nvidia RTX 2060 Super, which is more that suitable to run the necessary work for this course, and beyond. Below I have my secondary system's specifications listed via the good old `neofetch` command. If you cannot afford/have access to a system, use Google Collab to start, and look on the fastai Forum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Images/System-Specs.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"Images/System-Specs.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rationale behind my current system\n",
    "This system was thrown together with an older Dell Optiplex, and an Antec 900 case (which has exemplary cooling), some extra RAM (to be bring it up to 16GB), and adding in a 2060 Super (which is the crown jewel of this machine). This GPU features a good stock overclock, and a good cooling solution (allowing for it to run at full load, with minimal performance loss, and minimal noise).\n",
    "\n",
    "I chose to use PopOS! compared to my usual Arch install due to most frameworks having better support for Ubuntu based distros, and the fact that I was having trouble getting all of the frameworks working in Arch, and Nvidia Drivers were not playing well either in Arch. PopOS! provided a relatively simple setup experience, and allowed me to get up and running quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Your First Jupyter Notebook!\n",
    "Here I'll put in the fist piece of code that we are exposed to, and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.168157</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.047622</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>00:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#id first_training\n",
    "#caption Results from the first training\n",
    "# CLICK ME\n",
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "\n",
    "def is_cat(x): return x[0].isupper()\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat, item_tfms=Resize(224))\n",
    "\n",
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time it takes to train will depend on the GPU! As I am using quite modern hardware, it took an average time of about 30 seconds per epoch, and this process should not take more than 5 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that you are not expected to know that this code means yet! This will be explained later on, and to look at the Questionnaire at the end to look at what you should be learning."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
